{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22b926db",
   "metadata": {},
   "source": [
    "# Blind Spot Detection (BSD) with Active Intervention\n",
    "\n",
    "*Project for the course Smart Vehicular Systems (Academic Year 2024/2025).*\n",
    "\n",
    "**Name:** Pablo Sebastian\n",
    "\n",
    "**Surname:** Vargas Grateron\n",
    "\n",
    "**Email:** pablo.vargasgrateron@studio.unibo.it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8b0ea6",
   "metadata": {},
   "source": [
    "This project implements a blind spot detection system using [CARLA simulator](https://carla.org/) (Version 0.9.15) and MQTT for communication. The system detects vehicles in the blind spot of a simulated car and can trigger an active intervention if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fbd829",
   "metadata": {},
   "source": [
    "> Before running the code, ensure that the CARLA server is running and the MQTT broker is accessible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b455ec2",
   "metadata": {},
   "source": [
    "## Libraries and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8d24ad",
   "metadata": {},
   "source": [
    "To execute the code, you need to install the libraries listed in the `requirements.txt` file. You can install them using:\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "For the local imports, ensure that the `manual_control.py` and `manual_control_steeringwheel.py` files are in the same directory as this notebook or adjust the import path accordingly.\n",
    "\n",
    "> The local imports can be found in the CARLA repository under the `PythonAPI/examples` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999279d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla, time, pygame, math, random, cv2, os\n",
    "import numpy as np\n",
    "import paho.mqtt.client as mqtt\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Local imports\n",
    "import manual_control\n",
    "import manual_control_steeringwheel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a513980",
   "metadata": {},
   "source": [
    "This cell configures the CARLA server connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07e8445",
   "metadata": {},
   "outputs": [],
   "source": [
    "carla_client = carla.Client('localhost', 2000)\n",
    "carla_client.set_timeout(10.0)\n",
    "\n",
    "world = carla_client.get_world()\n",
    "spectator = world.get_spectator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe80d95",
   "metadata": {},
   "source": [
    "This cell configures the MQTT client. We will use the public broker `test.mosquitto.org` for testing purposes. In a production environment, you should use a secure and private MQTT broker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8909a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "BROKER = \"test.mosquitto.org\"\n",
    "PORT = 1883\n",
    "TOPIC = \"svs_blind_spot_detection\"\n",
    "\n",
    "mqtt_client = mqtt.Client()\n",
    "mqtt_client.connect(BROKER, PORT, 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02136aed",
   "metadata": {},
   "source": [
    "Further setup for the MQTT client, including connection and message handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577c2d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mqtt_on_connect(client, userdata, flags, rc):\n",
    "    \"\"\"\n",
    "    Callback function triggered when MQTT client connects to broker\n",
    "    - Automatically subscribes to the BSD topic once connected\n",
    "    - rc codes: 0=success, 1=wrong protocol, 2=invalid client ID, etc.\n",
    "    \"\"\"\n",
    "    print(f\"[MQTT] Connected (code {rc})\")\n",
    "    client.subscribe(TOPIC)\n",
    "\n",
    "def mqtt_on_message(client, userdata, message):\n",
    "    \"\"\"\n",
    "    Callback function triggered when a message is received on subscribed topics\n",
    "    - Decodes incoming messages and prints them\n",
    "    \"\"\"\n",
    "    decoded_message = message.payload.decode()\n",
    "    print(f\"[MQTT] Message on {message.topic} -> {decoded_message}\")\n",
    "\n",
    "def mqtt_send_message(topic, message):\n",
    "    \"\"\"\n",
    "    Send a message to specified MQTT topic\n",
    "    - Used to publish BSD alerts, status updates, or intervention commands\n",
    "    - Message format: string (will be encoded to bytes automatically)\n",
    "    \"\"\"\n",
    "    mqtt_client.publish(topic, message)\n",
    "    print(f\"[MQTT] Sent message: {message} to topic: {topic}\")\n",
    "\n",
    "mqtt_client.on_connect = mqtt_on_connect\n",
    "mqtt_client.on_message = mqtt_on_message    \n",
    "\n",
    "mqtt_client.loop_start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc24b592",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041057ed",
   "metadata": {},
   "source": [
    "### CARLA basic functions (From the laboratory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f641447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_spectator_to(transform, distance=5.0, x=0, y=0, z=4, yaw=0, pitch=-30, roll=0):\n",
    "    back_location = transform.location - transform.get_forward_vector() * distance\n",
    "    \n",
    "    back_location.x += x\n",
    "    back_location.y += y\n",
    "    back_location.z += z\n",
    "    transform.rotation.yaw += yaw\n",
    "    transform.rotation.pitch = pitch\n",
    "    transform.rotation.roll = roll\n",
    "    \n",
    "    spectator_transform = carla.Transform(back_location, transform.rotation)\n",
    "    \n",
    "    spectator.set_transform(spectator_transform)\n",
    "\n",
    "def spawn_vehicle(vehicle_index=0, spawn_index=0, pattern='vehicle.*'):\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    vehicle_bp = blueprint_library.filter(pattern)[vehicle_index]\n",
    "    spawn_point = world.get_map().get_spawn_points()[spawn_index]\n",
    "    vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "    return vehicle\n",
    "\n",
    "def draw_on_screen(world, transform, content='O', color=carla.Color(0, 255, 0), life_time=20):\n",
    "    world.debug.draw_string(transform.location, content, color=color, life_time=life_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419c97f0",
   "metadata": {},
   "source": [
    "### Computer vision functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0177604f",
   "metadata": {},
   "source": [
    "We will implement functions to capture images from the car's cameras and detect vehicles using [YOLOv11](https://docs.ultralytics.com/models/yolo11/) model. We will use the nano version for real-time processing.\n",
    "\n",
    "> Make sure to download the YOLOv11 nano model and place it in the `cv_model` directory (Or change the path in the code below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864fd30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"cv_model\"\n",
    "MODEL_NAME = \"yolo11n.pt\"\n",
    "\n",
    "cv_model_path = os.path.join(MODEL_DIR, MODEL_NAME)\n",
    "cv_model = YOLO(cv_model_path)\n",
    "\n",
    "def detect_vehicles(image, model=cv_model, conf=0.25):\n",
    "    \"\"\"\n",
    "    Detect vehicles in an image using YOLO model for blind spot detection\n",
    "    \n",
    "    Args:\n",
    "        image: NumPy array representing RGB image from camera\n",
    "        model: YOLOv11 model object (default: pre-loaded cv_model)\n",
    "        conf: Confidence threshold for detections (default: 0.25 = 25%)\n",
    "    \n",
    "    Returns:\n",
    "        list: List of vehicle detections, each containing:\n",
    "            - xmin, ymin, xmax, ymax: Bounding box coordinates in pixels\n",
    "            - confidence: Detection confidence score (0.0 to 1.0)\n",
    "            - class_id: YOLO class ID number\n",
    "            - label: Vehicle type ('car', 'truck', 'bus', 'motorcycle')\n",
    "    \"\"\"\n",
    "    results = model(image, conf=conf)\n",
    "    detections = []\n",
    "    \n",
    "    for result in results:\n",
    "        if result.boxes is not None:\n",
    "            for box in result.boxes:\n",
    "                label = model.names[int(box.cls[0])]\n",
    "                # Filter for vehicle classes (car, truck, bus, motorcycle)\n",
    "                if box.conf[0] > conf and label in ['car', 'truck', 'bus', 'motorcycle']:\n",
    "                    x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "                    detection = {\n",
    "                        'xmin': int(x1),\n",
    "                        'ymin': int(y1),\n",
    "                        'xmax': int(x2),\n",
    "                        'ymax': int(y2),\n",
    "                        'confidence': float(box.conf[0]),\n",
    "                        'class_id': int(box.cls[0]),\n",
    "                        'label': label\n",
    "                    }\n",
    "                    detections.append(detection)\n",
    "    \n",
    "    return detections\n",
    "\n",
    "def carla_image_to_array(image):\n",
    "    \"\"\"\n",
    "    Convert CARLA raw image data to NumPy RGB array for YOLO processing\n",
    "    \n",
    "    Args:\n",
    "        image: CARLA camera sensor image object with raw_data attribute\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: RGB image array (height, width, 3) suitable for YOLO\n",
    "    \"\"\"\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    array = array.reshape((image.height, image.width, 4))\n",
    "    array = array[:, :, :3]\n",
    "    array = array[:, :, [2, 1, 0]] # Convert BGR to RGB\n",
    "    return array\n",
    "\n",
    "def process_camera_image(image):\n",
    "    \"\"\"\n",
    "    Complete pipeline: Convert CARLA image and detect vehicles for BSD system\n",
    "    \n",
    "    Args:\n",
    "        image: CARLA camera sensor image object\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (rgb_array, detections)\n",
    "            - rgb_array: Converted RGB image as NumPy array\n",
    "            - detections: List of vehicle detections from YOLO\n",
    "    \"\"\"\n",
    "    rgb_array = carla_image_to_array(image)\n",
    "    detections = detect_vehicles(rgb_array)\n",
    "    \n",
    "    if detections:\n",
    "        print(f\"Detected {len(detections)} vehicles:\")\n",
    "        for det in detections:\n",
    "            print(f\"  - {det['label']}: {det['confidence']:.2f} confidence\")\n",
    "    \n",
    "    return rgb_array, detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7154e077",
   "metadata": {},
   "source": [
    "### Sensors functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e92df6",
   "metadata": {},
   "source": [
    "The next cells implement the functions to spawn:\n",
    "\n",
    "- The **camera sensors** to capture image to further process with YOLOv5 and detect vehicles.\n",
    "- The **radar sensor** to detect vehicles in the blind spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500c9f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spawn_camera(attach_to=None, transform=carla.Transform(carla.Location(x=0.0, y=0.0, z=1.0), carla.Rotation(pitch=0)), width=800, height=600):\n",
    "    \"\"\"\n",
    "    Spawn an RGB camera sensor in the CARLA world for vehicle detection\n",
    "    \n",
    "    Args:\n",
    "        attach_to: Vehicle or object to attach camera to (None = spawn freely)\n",
    "        transform: Camera position and orientation relative to attachment point\n",
    "        width: Image width in pixels (default: 800)\n",
    "        height: Image height in pixels (default: 600)\n",
    "    \n",
    "    Returns:\n",
    "        carla.Sensor: RGB camera sensor object for capturing images\n",
    "    \"\"\"\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', str(width))\n",
    "    camera_bp.set_attribute('image_size_y', str(height))\n",
    "    camera = world.spawn_actor(camera_bp, transform, attach_to=attach_to)\n",
    "    return camera\n",
    "\n",
    "def spawn_radar(attach_to=None, transform=carla.Transform(carla.Location(x=0.0, y=0.0, z=1.0), carla.Rotation(pitch=0)), range=100, horizontal_fov=30, vertical_fov=30):\n",
    "    \"\"\"\n",
    "    Spawn a radar sensor in the CARLA world for object detection\n",
    "    \n",
    "    Args:\n",
    "        attach_to: Vehicle or object to attach radar to (None = spawn freely)\n",
    "        transform: Radar position and orientation relative to attachment point\n",
    "        range: Detection range in meters (default: 100m)\n",
    "        horizontal_fov: Horizontal field of view in degrees (default: 30°)\n",
    "        vertical_fov: Vertical field of view in degrees (default: 30°)\n",
    "    \n",
    "    Returns:\n",
    "        carla.Sensor: Radar sensor object for detecting nearby objects\n",
    "    \"\"\"\n",
    "    radar_bp = world.get_blueprint_library().find('sensor.other.radar')\n",
    "    radar_bp.set_attribute('horizontal_fov', str(horizontal_fov))\n",
    "    radar_bp.set_attribute('vertical_fov', str(vertical_fov))\n",
    "    radar_bp.set_attribute('range', str(range))\n",
    "    radar = world.spawn_actor(radar_bp, transform, attach_to=attach_to)\n",
    "    return radar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec1d546",
   "metadata": {},
   "source": [
    "## Main program and code execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1774d6ca",
   "metadata": {},
   "source": [
    "### World setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26ca323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b7ed2b5",
   "metadata": {},
   "source": [
    "### Car setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476e0dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11e983cf",
   "metadata": {},
   "source": [
    "### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c7558e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
