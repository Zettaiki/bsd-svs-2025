{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22b926db",
   "metadata": {},
   "source": [
    "# Blind Spot Detection (BSD) with Active Intervention\n",
    "\n",
    "*Project for the course Smart Vehicular Systems (Academic Year 2024/2025).*\n",
    "\n",
    "**Name:** Pablo Sebastian\n",
    "\n",
    "**Surname:** Vargas Grateron\n",
    "\n",
    "**Email:** pablo.vargasgrateron@studio.unibo.it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8b0ea6",
   "metadata": {},
   "source": [
    "This project implements a blind spot detection system using [CARLA simulator](https://carla.org/) (Version 0.9.15) and MQTT for communication. The system detects vehicles in the blind spot of a simulated car and can trigger an active intervention if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fbd829",
   "metadata": {},
   "source": [
    "> Before running the code, ensure that the CARLA server is running and the MQTT broker is accessible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b455ec2",
   "metadata": {},
   "source": [
    "## Libraries and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8d24ad",
   "metadata": {},
   "source": [
    "To execute the code, you need to install the libraries listed in the `requirements.txt` file. You can install them using:\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "For the local imports, ensure that the `manual_control.py` and `manual_control_steeringwheel.py` files are in the same directory as this notebook or adjust the import path accordingly.\n",
    "\n",
    "> The local imports can be found in the CARLA repository under the `PythonAPI/examples` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "999279d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.7.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import carla, time, pygame, math, random, cv2, os\n",
    "import numpy as np\n",
    "import paho.mqtt.client as mqtt\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Local imports\n",
    "import manual_control\n",
    "import manual_control_steeringwheel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d175b97",
   "metadata": {},
   "source": [
    "Set the following boolean to `False` if you want to use the keyboard control instead of the steering wheel, or set it to `True` if you want to use the steering wheel control.\n",
    "Set the `CAR_MODEL` to the desired vehicle model you want to use in the simulation. You can find a list of available vehicle models in [this list](https://github.com/carla-simulator/carla/blob/ue5-dev/Docs/catalogue_vehicles.md#audi-tt).\n",
    "\n",
    "> Remember to set the `wheel_config.ini` file in the same directory as this notebook to configure the steering wheel settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec2e2c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_STEERING_WHEEL = False\n",
    "CAR_MODEL = \"vehicle.audi.tt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a513980",
   "metadata": {},
   "source": [
    "This cell configures the CARLA server connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f07e8445",
   "metadata": {},
   "outputs": [],
   "source": [
    "CARLA_HOST = 'localhost'\n",
    "CARLA_PORT = 2000\n",
    "CARLA_TIMEOUT = 10.0\n",
    "\n",
    "carla_client = carla.Client(CARLA_HOST, CARLA_PORT)\n",
    "carla_client.set_timeout(CARLA_TIMEOUT)\n",
    "\n",
    "world = carla_client.get_world()\n",
    "spectator = world.get_spectator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe80d95",
   "metadata": {},
   "source": [
    "This cell configures the MQTT client. We will use the public broker `test.mosquitto.org` for testing purposes. In a production environment, you should use a secure and private MQTT broker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8909a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pseba\\.conda\\envs\\carla-env\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Callback API version 1 is deprecated, update to latest version\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MQTTErrorCode.MQTT_ERR_SUCCESS: 0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MQTT_BROKER = \"test.mosquitto.org\"\n",
    "MQTT_PORT = 1883\n",
    "MQTT_TOPIC = \"svs_blind_spot_detection\"\n",
    "\n",
    "mqtt_client = mqtt.Client()\n",
    "mqtt_client.connect(MQTT_BROKER, MQTT_PORT, 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc24b592",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041057ed",
   "metadata": {},
   "source": [
    "### CARLA basic functions (From the laboratory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f641447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_spectator_to(transform, distance=5.0, x=0, y=0, z=4, yaw=0, pitch=-30, roll=0):\n",
    "    back_location = transform.location - transform.get_forward_vector() * distance\n",
    "    \n",
    "    back_location.x += x\n",
    "    back_location.y += y\n",
    "    back_location.z += z\n",
    "    transform.rotation.yaw += yaw\n",
    "    transform.rotation.pitch = pitch\n",
    "    transform.rotation.roll = roll\n",
    "    \n",
    "    spectator_transform = carla.Transform(back_location, transform.rotation)\n",
    "    \n",
    "    spectator.set_transform(spectator_transform)\n",
    "\n",
    "def spawn_vehicle(vehicle_index=0, spawn_index=0, pattern='vehicle.*'):\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    vehicle_bp = blueprint_library.filter(pattern)[vehicle_index]\n",
    "    spawn_point = world.get_map().get_spawn_points()[spawn_index]\n",
    "    vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "    return vehicle\n",
    "\n",
    "def draw_on_screen(world, transform, content='O', color=carla.Color(0, 255, 0), life_time=20):\n",
    "    world.debug.draw_string(transform.location, content, color=color, life_time=life_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5f11ab",
   "metadata": {},
   "source": [
    "### MQTT functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb626b58",
   "metadata": {},
   "source": [
    "Further setup for the MQTT client, including connection and message handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d83c2565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MQTTErrorCode.MQTT_ERR_SUCCESS: 0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mqtt_on_connect(client, userdata, flags, rc):\n",
    "    \"\"\"\n",
    "    Callback function triggered when MQTT client connects to broker\n",
    "    - Automatically subscribes to the BSD topic once connected\n",
    "    - rc codes: 0=success, 1=wrong protocol, 2=invalid client ID, etc.\n",
    "    \"\"\"\n",
    "    print(f\"INFO: [MQTT] Connected (code {rc})\")\n",
    "    client.subscribe(MQTT_TOPIC)\n",
    "\n",
    "def mqtt_on_message(client, userdata, message):\n",
    "    \"\"\"\n",
    "    Callback function triggered when a message is received on subscribed topics\n",
    "    - Decodes incoming messages and prints them\n",
    "    \"\"\"\n",
    "    decoded_message = message.payload.decode()\n",
    "    print(f\"INFO: [MQTT] Message on {message.topic} -> {decoded_message}\")\n",
    "\n",
    "def mqtt_send_message(topic, message):\n",
    "    \"\"\"\n",
    "    Send a message to specified MQTT topic\n",
    "    - Used to publish BSD alerts, status updates, or intervention commands\n",
    "    - Message format: string (will be encoded to bytes automatically)\n",
    "    \"\"\"\n",
    "    mqtt_client.publish(topic, message)\n",
    "    print(f\"INFO: [MQTT] Sent message: {message} to topic: {topic}\")\n",
    "\n",
    "mqtt_client.on_connect = mqtt_on_connect\n",
    "mqtt_client.on_message = mqtt_on_message    \n",
    "\n",
    "mqtt_client.loop_start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419c97f0",
   "metadata": {},
   "source": [
    "### Computer vision functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0177604f",
   "metadata": {},
   "source": [
    "We will implement functions to capture images from the car's cameras and detect vehicles using [YOLOv5](https://docs.ultralytics.com/models/yolov5/) model. We will use the nano version for real-time processing.\n",
    "\n",
    "> Make sure to download the YOLOv5 nano model and place it in the `cv_model` directory (Or change the path in the code below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "864fd30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = os.path.join(os.getcwd(), \"cv_model\")\n",
    "MODEL_NAME = \"yolov5nu.pt\"\n",
    "\n",
    "cv_model_path = os.path.join(MODEL_DIR, MODEL_NAME)\n",
    "cv_model = YOLO(cv_model_path)\n",
    "\n",
    "def detect_vehicles(image, model=cv_model, conf=0.25):\n",
    "    \"\"\"\n",
    "    Detect vehicles (car, truck, bus, motorcycle) in an image using YOLOv5.\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): Input image in RGB format.\n",
    "        model: YOLOv5 model.\n",
    "        conf (float): Confidence threshold (default: 0.25).\n",
    "\n",
    "    Returns:\n",
    "        list of dict: Detected vehicles with bounding box and class info.\n",
    "    \"\"\"\n",
    "    results = model(image)\n",
    "    \n",
    "    # Results in tensor [x1, y1, x2, y2, conf, class]\n",
    "    predictions = results.xyxy[0].cpu().numpy()\n",
    "    detections = []\n",
    "\n",
    "    for pred in predictions:\n",
    "        x1, y1, x2, y2, confidence, class_id = pred\n",
    "        if confidence >= conf:\n",
    "            label = model.names[int(class_id)]\n",
    "            if label in ['car', 'truck', 'bus', 'motorcycle']:\n",
    "                detections.append({\n",
    "                    'xmin': int(x1),\n",
    "                    'ymin': int(y1),\n",
    "                    'xmax': int(x2),\n",
    "                    'ymax': int(y2),\n",
    "                    'confidence': float(confidence),\n",
    "                    'class_id': int(class_id),\n",
    "                    'label': label\n",
    "                })\n",
    "\n",
    "    return detections\n",
    "\n",
    "def carla_image_to_array(image):\n",
    "    \"\"\"\n",
    "    Convert CARLA raw image data to NumPy RGB array for YOLO processing\n",
    "    \n",
    "    Args:\n",
    "        image: CARLA camera sensor image object with raw_data attribute\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: RGB image array (height, width, 3) suitable for YOLO\n",
    "    \"\"\"\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    array = array.reshape((image.height, image.width, 4))\n",
    "    array = array[:, :, :3]\n",
    "    array = array[:, :, [2, 1, 0]] # Convert BGR to RGB\n",
    "    return array\n",
    "\n",
    "def process_camera_image(image):\n",
    "    \"\"\"\n",
    "    Complete pipeline: Convert CARLA image and detect vehicles for BSD system\n",
    "    \n",
    "    Args:\n",
    "        image: CARLA camera sensor image object\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (rgb_array, detections)\n",
    "            - rgb_array: Converted RGB image as NumPy array\n",
    "            - detections: List of vehicle detections from YOLO\n",
    "    \"\"\"\n",
    "    rgb_array = carla_image_to_array(image)\n",
    "    detections = detect_vehicles(rgb_array)\n",
    "    \n",
    "    if detections:\n",
    "        print(f\"Detected {len(detections)} vehicles:\")\n",
    "        for det in detections:\n",
    "            print(f\"  - {det['label']}: {det['confidence']:.2f} confidence\")\n",
    "    \n",
    "    return rgb_array, detections\n",
    "\n",
    "def detect_car_in_sensor(image):\n",
    "    \"\"\"\n",
    "    Detect cars in the given sensor image using YOLOv5.\n",
    "\n",
    "    Args:\n",
    "        image: CARLA camera sensor image object.\n",
    "\n",
    "    Returns:\n",
    "        list: Detected car bounding boxes and labels.\n",
    "    \"\"\"\n",
    "    rgb_array, detections = process_camera_image(image)\n",
    "    \n",
    "    if not detections:\n",
    "        print(\"[CAR DETECTION] No cars detected.\")\n",
    "        return False\n",
    "    if detections:\n",
    "        print(f\"[CAR DETECTION] Detected {len(detections)} cars.\")\n",
    "        for det in detections:\n",
    "            if det['confidence'] > 0.5:\n",
    "                print(f\"[CAR DETECTION] Car detected: {det['label']} with confidence {det['confidence']:.2f}\")\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7154e077",
   "metadata": {},
   "source": [
    "### Sensors functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e92df6",
   "metadata": {},
   "source": [
    "The next cells implement the functions to spawn:\n",
    "\n",
    "- The **camera sensors** to capture image to further process with YOLOv5 and detect vehicles.\n",
    "- The **radar sensor** to detect vehicles in the blind spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "500c9f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spawn_camera(attach_to=None, transform=carla.Transform(carla.Location(x=0.0, y=0.0, z=1.0), carla.Rotation(pitch=0)), width=800, height=600):\n",
    "    \"\"\"\n",
    "    Spawn an RGB camera sensor in the CARLA world for vehicle detection\n",
    "    \n",
    "    Args:\n",
    "        attach_to: Vehicle or object to attach camera to (None = spawn freely)\n",
    "        transform: Camera position and orientation relative to attachment point\n",
    "        width: Image width in pixels (default: 800)\n",
    "        height: Image height in pixels (default: 600)\n",
    "    \n",
    "    Returns:\n",
    "        carla.Sensor: RGB camera sensor object for capturing images\n",
    "    \"\"\"\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', str(width))\n",
    "    camera_bp.set_attribute('image_size_y', str(height))\n",
    "    camera = world.spawn_actor(camera_bp, transform, attach_to=attach_to)\n",
    "    return camera\n",
    "\n",
    "def spawn_radar(attach_to=None, transform=carla.Transform(carla.Location(x=0.0, y=0.0, z=1.0), carla.Rotation(pitch=0)), range=100, horizontal_fov=30, vertical_fov=30):\n",
    "    \"\"\"\n",
    "    Spawn a radar sensor in the CARLA world for object detection\n",
    "    \n",
    "    Args:\n",
    "        attach_to: Vehicle or object to attach radar to (None = spawn freely)\n",
    "        transform: Radar position and orientation relative to attachment point\n",
    "        range: Detection range in meters (default: 100m)\n",
    "        horizontal_fov: Horizontal field of view in degrees (default: 30°)\n",
    "        vertical_fov: Vertical field of view in degrees (default: 30°)\n",
    "    \n",
    "    Returns:\n",
    "        carla.Sensor: Radar sensor object for detecting nearby objects\n",
    "    \"\"\"\n",
    "    radar_bp = world.get_blueprint_library().find('sensor.other.radar')\n",
    "    radar_bp.set_attribute('horizontal_fov', str(horizontal_fov))\n",
    "    radar_bp.set_attribute('vertical_fov', str(vertical_fov))\n",
    "    radar_bp.set_attribute('range', str(range))\n",
    "    radar = world.spawn_actor(radar_bp, transform, attach_to=attach_to)\n",
    "    return radar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac54fec",
   "metadata": {},
   "source": [
    "### Debug functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953e13f4",
   "metadata": {},
   "source": [
    "The following cells contain debug functions to visualize different sensors data inside the CARLA simulator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae0d903",
   "metadata": {},
   "source": [
    "#### Sensor placement check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1653bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_draw_sensor_placement(vehicle, camera_left, camera_right, radar_left_side, radar_right_side, radar_left_rear, radar_right_rear):\n",
    "    \"\"\"\n",
    "    Draw sensor placements on the CARLA world for debugging\n",
    "    \n",
    "    Args:\n",
    "        vehicle: Vehicle actor to draw sensors on\n",
    "        camera_left: Left camera sensor actor\n",
    "        camera_right: Right camera sensor actor\n",
    "        radar_left_side: Left side radar sensor actor\n",
    "        radar_right_side: Right side radar sensor actor\n",
    "        radar_left_rear: Left rear radar sensor actor\n",
    "        radar_right_rear: Right rear radar sensor actor\n",
    "    \"\"\"\n",
    "    draw_on_screen(world, camera_left.get_transform(), content='Camera Left', color=carla.Color(0, 255, 0))\n",
    "    draw_on_screen(world, camera_right.get_transform(), content='Camera Right', color=carla.Color(0, 255, 0))\n",
    "    draw_on_screen(world, radar_left_side.get_transform(), content='Radar Left Side', color=carla.Color(255, 0, 0))\n",
    "    draw_on_screen(world, radar_right_side.get_transform(), content='Radar Right Side', color=carla.Color(255, 0, 0))\n",
    "    draw_on_screen(world, radar_left_rear.get_transform(), content='Radar Left Rear', color=carla.Color(255, 0, 0))\n",
    "    draw_on_screen(world, radar_right_rear.get_transform(), content='Radar Right Rear', color=carla.Color(255, 0, 0))\n",
    "    move_spectator_to(vehicle.get_transform(), distance=10, x=0, y=0, z=4, yaw=0, pitch=-30, roll=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3388c6",
   "metadata": {},
   "source": [
    "#### Radar cone visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dc66c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_point(x, y, z, rotation):\n",
    "    \"\"\"\n",
    "    Rotate point (x, y, z) by CARLA rotation (pitch, yaw, roll) in degrees.\n",
    "    \"\"\"\n",
    "    # Convert degrees to radians\n",
    "    pitch = math.radians(rotation.pitch)\n",
    "    yaw = math.radians(rotation.yaw)\n",
    "    roll = math.radians(rotation.roll)\n",
    "\n",
    "    # Apply yaw (Z-axis)\n",
    "    x_yaw = x * math.cos(yaw) - y * math.sin(yaw)\n",
    "    y_yaw = x * math.sin(yaw) + y * math.cos(yaw)\n",
    "    z_yaw = z\n",
    "\n",
    "    # Apply pitch (Y-axis)\n",
    "    x_pitch = x_yaw * math.cos(pitch) + z_yaw * math.sin(pitch)\n",
    "    y_pitch = y_yaw\n",
    "    z_pitch = -x_yaw * math.sin(pitch) + z_yaw * math.cos(pitch)\n",
    "\n",
    "    # Apply roll (X-axis)\n",
    "    x_roll = x_pitch\n",
    "    y_roll = y_pitch * math.cos(roll) - z_pitch * math.sin(roll)\n",
    "    z_roll = y_pitch * math.sin(roll) + z_pitch * math.cos(roll)\n",
    "\n",
    "    return x_roll, y_roll, z_roll\n",
    "\n",
    "\n",
    "def debug_draw_cone(actor, horizontal_fov=30.0, vertical_fov=10.0, range_m=20.0):\n",
    "    \"\"\"\n",
    "    Draw the radar's field of view cone considering its orientation.\n",
    "    \"\"\"\n",
    "    world = actor.get_world()\n",
    "    transform = actor.get_transform()\n",
    "    radar_location = transform.location\n",
    "    radar_rotation = transform.rotation\n",
    "\n",
    "    # Half-angles in radians\n",
    "    h_fov = math.radians(horizontal_fov / 2)\n",
    "    v_fov = math.radians(vertical_fov / 2)\n",
    "\n",
    "    # Local points (relative to radar)\n",
    "    local_points = []\n",
    "    for yaw in [-h_fov, h_fov]:\n",
    "        for pitch in [-v_fov, v_fov]:\n",
    "            x = range_m * math.cos(pitch) * math.cos(yaw)\n",
    "            y = range_m * math.cos(pitch) * math.sin(yaw)\n",
    "            z = range_m * math.sin(pitch)\n",
    "            local_points.append((x, y, z))\n",
    "\n",
    "    # Transform local points to world coordinates\n",
    "    world_points = []\n",
    "    for (x, y, z) in local_points:\n",
    "        x_r, y_r, z_r = rotate_point(x, y, z, radar_rotation)\n",
    "        world_points.append(radar_location + carla.Location(x=x_r, y=y_r, z=z_r))\n",
    "\n",
    "    # Draw lines from radar to each corner\n",
    "    for p in world_points:\n",
    "        world.debug.draw_line(radar_location, p, thickness=0.05, color=carla.Color(0, 255, 0), life_time=20)\n",
    "\n",
    "    # Draw the rectangle connecting the far points\n",
    "    world.debug.draw_line(world_points[0], world_points[1], thickness=0.05, color=carla.Color(0, 255, 0), life_time=20)\n",
    "    world.debug.draw_line(world_points[1], world_points[3], thickness=0.05, color=carla.Color(0, 255, 0), life_time=20)\n",
    "    world.debug.draw_line(world_points[3], world_points[2], thickness=0.05, color=carla.Color(0, 255, 0), life_time=20)\n",
    "    world.debug.draw_line(world_points[2], world_points[0], thickness=0.05, color=carla.Color(0, 255, 0), life_time=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec1d546",
   "metadata": {},
   "source": [
    "## Main loop code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4787433",
   "metadata": {},
   "source": [
    "### Debug flag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311cc40b",
   "metadata": {},
   "source": [
    "Debug flags to enable or disable debug features. These features are useful for visualizing sensor placements and radar cones in the CARLA simulator and are purely for debugging purposes.\n",
    "\n",
    "> **WARNING:** Is recommended to set only one debug flag to `True` at a time to avoid overlapping tags, drawings and misplacement of the cameras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3029090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG_DRAW_SENSOR_PLACEMENT = False\n",
    "DEBUG_DRAW_RADAR_CONE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4cf7e5",
   "metadata": {},
   "source": [
    "### Sensor parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8732f2",
   "metadata": {},
   "source": [
    "The next cell contains the parameters of the sensors. These parameters define the pitch, yaw and FOV of the sensors, as well as the range of the radar sensors. The parameters are used to spawn the sensors in the CARLA simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853f6274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pitch and yaw angles for the cameras and radars\n",
    "\n",
    "CAMERA_LEFT_PITCH = 0\n",
    "CAMERA_LEFT_YAW = -150\n",
    "CAMERA_RIGHT_PITCH = 0\n",
    "CAMERA_RIGHT_YAW = 150\n",
    "\n",
    "RADAR_SIDE_LEFT_PITCH = 0\n",
    "RADAR_SIDE_LEFT_YAW = -100\n",
    "RADAR_SIDE_RIGHT_PITCH = 0\n",
    "RADAR_SIDE_RIGHT_YAW = 100\n",
    "\n",
    "RADAR_REAR_LEFT_PITCH = 0\n",
    "RADAR_REAR_LEFT_YAW = -165\n",
    "RADAR_REAR_RIGHT_PITCH = 0\n",
    "RADAR_REAR_RIGHT_YAW = 165\n",
    "\n",
    "# FOV of the radars\n",
    "\n",
    "RADAR_SIDE_HORIZONTAL_FOV = 100.0\n",
    "RADAR_SIDE_VERTICAL_FOV = 15.0\n",
    "RADAR_SIDE_RANGE = 6.0\n",
    "\n",
    "RADAR_REAR_HORIZONTAL_FOV = 30.0\n",
    "RADAR_REAR_VERTICAL_FOV = 10.0\n",
    "RADAR_REAR_RANGE = 10.0\n",
    "\n",
    "# Speed THRESHOLD for rear radars\n",
    "REAR_RADAR_SPEED_THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a53c88",
   "metadata": {},
   "source": [
    "### Car setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc90bdcf",
   "metadata": {},
   "source": [
    "The following cell contains the setup for the car and its sensors. It includes the car's position, orientation, and the sensors to be used for blind spot detection.\n",
    "\n",
    "The cameras and the radar sensors on the sides are atached near the side mirrors of the car, while the rear sensors are placed at the back of the car, near the rear lights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4680ffcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_player_vehicle(vehicle):\n",
    "    \"\"\"\n",
    "    Setup sensors for the player vehicle in the CARLA world.\n",
    "\n",
    "    Args:\n",
    "        vehicle: The vehicle actor to attach sensors to.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Contains the camera and radar sensors attached to the vehicle.\n",
    "    \"\"\"\n",
    "    camera_left = spawn_camera(attach_to=vehicle, transform=carla.Transform(carla.Location(x=0.3, y=-1.0, z=0.5), \n",
    "                                                                                carla.Rotation(pitch=CAMERA_LEFT_PITCH, yaw=CAMERA_LEFT_YAW, roll=0)))\n",
    "    camera_right = spawn_camera(attach_to=vehicle, transform=carla.Transform(carla.Location(x=0.3, y=1.0, z=0.5), \n",
    "                                                                                carla.Rotation(pitch=CAMERA_RIGHT_PITCH, yaw=CAMERA_RIGHT_YAW, roll=0)))\n",
    "\n",
    "    radar_left_side = spawn_radar(attach_to=vehicle, transform=carla.Transform(carla.Location(x=-1.0, y=-1.0, z=0.5), \n",
    "                                                                                carla.Rotation(pitch=RADAR_SIDE_LEFT_PITCH, yaw=RADAR_SIDE_LEFT_YAW, roll=0)), \n",
    "                                                                                range=RADAR_SIDE_RANGE, horizontal_fov=RADAR_SIDE_HORIZONTAL_FOV, vertical_fov=RADAR_SIDE_VERTICAL_FOV)\n",
    "    radar_right_side = spawn_radar(attach_to=vehicle, transform=carla.Transform(carla.Location(x=-1.0, y=1.0, z=0.5), \n",
    "                                                                                carla.Rotation(pitch=RADAR_SIDE_RIGHT_PITCH, yaw=RADAR_SIDE_RIGHT_YAW, roll=0)), \n",
    "                                                                                range=RADAR_SIDE_RANGE, horizontal_fov=RADAR_SIDE_HORIZONTAL_FOV, vertical_fov=RADAR_SIDE_VERTICAL_FOV)\n",
    "\n",
    "    radar_left_rear = spawn_radar(attach_to=vehicle, transform=carla.Transform(carla.Location(x=-2.0, y=-1.0, z=0.5), \n",
    "                                                                                carla.Rotation(pitch=RADAR_REAR_LEFT_PITCH, yaw=RADAR_REAR_LEFT_YAW, roll=0)), \n",
    "                                                                                range=RADAR_REAR_RANGE, horizontal_fov=RADAR_REAR_HORIZONTAL_FOV, vertical_fov=RADAR_REAR_VERTICAL_FOV)\n",
    "    radar_right_rear = spawn_radar(attach_to=vehicle, transform=carla.Transform(carla.Location(x=-2.0, y=1.0, z=0.5), \n",
    "                                                                                carla.Rotation(pitch=RADAR_REAR_RIGHT_PITCH, yaw=RADAR_REAR_RIGHT_YAW, roll=0)), \n",
    "                                                                                range=RADAR_REAR_RANGE, horizontal_fov=RADAR_REAR_HORIZONTAL_FOV, vertical_fov=RADAR_REAR_VERTICAL_FOV)\n",
    "\n",
    "    return (camera_left, camera_right, radar_left_side, radar_right_side, radar_left_rear, radar_right_rear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4e4ff9",
   "metadata": {},
   "source": [
    "### Listeners setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd43e69a",
   "metadata": {},
   "source": [
    "The following cell sets up the listeners for the sensors. The listeners are used to receive the data from the sensors and process it.\n",
    "\n",
    "Depending on the type of sensor, the data is processed differently. For example, the camera sensors capture images and process them with YOLOv5 to detect vehicles, while the radar sensors detect vehicles in the blind spot.\n",
    "\n",
    "While the side radars tell if there is a vehicle in the blind spot by only checking the presence of a vehicle, the rear radars also check the speed of the vehicle to determine if it is approaching or moving away from the car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d91406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def radar_side_callback(data):\n",
    "    \"\"\"\n",
    "    Callback function for radar sensor data.\n",
    "    - Processes radar data to detect objects in the blind spot.\n",
    "    \"\"\"\n",
    "    for detection in data:\n",
    "        if detection.depth < RADAR_SIDE_RANGE:\n",
    "            # TODO: Queue detection data for further processing\n",
    "            pass  \n",
    "    \n",
    "\n",
    "def radar_rear_callback(data):\n",
    "    \"\"\"\n",
    "    Callback function for rear radar sensor data.\n",
    "    - Processes radar data to detect moving objects in the rear blind spot.\n",
    "    \"\"\"\n",
    "    for detection in data:\n",
    "        if detection.depth < RADAR_REAR_RANGE and detection.velocity > REAR_RADAR_SPEED_THRESHOLD:\n",
    "            # TODO: Queue detection data for further processing\n",
    "            pass\n",
    "\n",
    "def camera_callback(data):\n",
    "    \"\"\"\n",
    "    Callback function for camera sensor data.\n",
    "    \"\"\"\n",
    "    is_car_detected = detect_car_in_sensor(data)\n",
    "    if is_car_detected:\n",
    "        # TODO: Queue detection data for further processing\n",
    "        pass\n",
    "    else:\n",
    "        # TODO: Queue detection data for further processing\n",
    "        pass\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10219934",
   "metadata": {},
   "source": [
    "### Game loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faedb953",
   "metadata": {},
   "source": [
    "The following cell contains the game loop and the main function to run the CARLA simulation. It initializes the world, spawns the car, and starts the sensors.\n",
    "\n",
    "> Most of the code is extracted from the `manual_control.py` and `manual_control_steeringwheel.py` files from the CARLA repository. The code is adapted to this project needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c62aa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_loop(args, client=None, sim_world=None):\n",
    "    pygame.init()\n",
    "    pygame.font.init()\n",
    "    world = None\n",
    "    original_settings = None\n",
    "\n",
    "    try:\n",
    "        if client is None:\n",
    "            client = carla.Client(args.host, args.port)\n",
    "            client.set_timeout(10.0)\n",
    "        else:\n",
    "            manual_control.logging.info(\"[GAMELOOP] -> Using existing CARLA client instance\")\n",
    "\n",
    "        if sim_world is None:\n",
    "            sim_world = client.get_world()\n",
    "        else:\n",
    "            manual_control.logging.info(\"[GAMELOOP] -> Using existing CARLA world instance\")\n",
    "\n",
    "        if args.sync:\n",
    "            original_settings = sim_world.get_settings()\n",
    "            settings = sim_world.get_settings()\n",
    "            if not settings.synchronous_mode:\n",
    "                settings.synchronous_mode = True\n",
    "                settings.fixed_delta_seconds = 0.05\n",
    "            sim_world.apply_settings(settings)\n",
    "\n",
    "            traffic_manager = client.get_trafficmanager()\n",
    "            traffic_manager.set_synchronous_mode(True)\n",
    "\n",
    "        if args.autopilot and not sim_world.get_settings().synchronous_mode:\n",
    "            manual_control.logging.info(\"[GAMELOOP] -> WARNING: You are currently in asynchronous mode and could \"\n",
    "                  \"experience some issues with the traffic simulation\")\n",
    "\n",
    "        display = pygame.display.set_mode(\n",
    "            (args.width, args.height),\n",
    "            pygame.HWSURFACE | pygame.DOUBLEBUF)\n",
    "        display.fill((0,0,0))\n",
    "        pygame.display.flip()\n",
    "\n",
    "        hud = manual_control.HUD(args.width, args.height)\n",
    "        world = manual_control.World(sim_world, hud, args)\n",
    "\n",
    "        # Get the first vehicle in the world and setup the sensors\n",
    "        player_vehicle = sim_world.get_actors().filter('vehicle.*')[0]\n",
    "        camera_left, camera_right, radar_left_side, radar_right_side, radar_left_rear, radar_right_rear = setup_player_vehicle(player_vehicle)\n",
    "        manual_control.logging.info(\"[GAMELOOP] -> Vehicle sensors setup complete\")\n",
    "        \n",
    "        # [DEBUG] Draw position of sensors\n",
    "        if DEBUG_DRAW_SENSOR_PLACEMENT:\n",
    "            debug_draw_sensor_placement(player_vehicle, camera_left, camera_right, radar_left_side, radar_right_side, radar_left_rear, radar_right_rear)\n",
    "            move_spectator_to(player_vehicle.get_transform(), distance=10, x=0, y=0, z=4, yaw=0, pitch=-30, roll=0)\n",
    "\n",
    "        # [DEBUG] Draw radar cones\n",
    "        if DEBUG_DRAW_RADAR_CONE:\n",
    "            debug_draw_cone(radar_left_side, horizontal_fov=RADAR_SIDE_HORIZONTAL_FOV, vertical_fov=RADAR_SIDE_VERTICAL_FOV, range_m=RADAR_SIDE_RANGE)\n",
    "            debug_draw_cone(radar_right_side, horizontal_fov=RADAR_SIDE_HORIZONTAL_FOV, vertical_fov=RADAR_SIDE_VERTICAL_FOV, range_m=RADAR_SIDE_RANGE)\n",
    "            debug_draw_cone(radar_left_rear, horizontal_fov=RADAR_REAR_HORIZONTAL_FOV, vertical_fov=RADAR_REAR_VERTICAL_FOV, range_m=RADAR_REAR_RANGE)\n",
    "            debug_draw_cone(radar_right_rear, horizontal_fov=RADAR_REAR_HORIZONTAL_FOV, vertical_fov=RADAR_REAR_VERTICAL_FOV, range_m=RADAR_REAR_RANGE)\n",
    "            move_spectator_to(player_vehicle.get_transform(), distance=20, x=0, y=0, z=6, yaw=0, pitch=-40, roll=0)\n",
    "\n",
    "        # Register camera and radar callbacks\n",
    "        camera_left.listen(lambda data: camera_callback(data))\n",
    "        camera_right.listen(lambda data: camera_callback(data))\n",
    "        radar_left_side.listen(lambda data: radar_side_callback(data))\n",
    "        radar_right_side.listen(lambda data: radar_side_callback(data))\n",
    "        radar_left_rear.listen(lambda data: radar_rear_callback(data))\n",
    "        radar_right_rear.listen(lambda data: radar_rear_callback(data))\n",
    "        manual_control.logging.info(\"[GAMELOOP] -> Sensors registered and listening for data\")\n",
    "        \n",
    "        # Create controller based on user input\n",
    "        controller = None\n",
    "        if args.steering_wheel:\n",
    "            controller = manual_control_steeringwheel.DualControl(world, args.autopilot)\n",
    "            manual_control.logging.info(\"[GAMELOOP] -> Controller initialized with STEERING WHEEL support\")\n",
    "        else:\n",
    "            controller = manual_control.KeyboardControl(world, args.autopilot)\n",
    "            manual_control.logging.info(\"[GAMELOOP] -> Controller initialized with KEYBOARD support\")\n",
    "\n",
    "        if args.sync:\n",
    "            sim_world.tick()\n",
    "        else:\n",
    "            sim_world.wait_for_tick()\n",
    "\n",
    "        ## ========================================\n",
    "        ## ======== GAME LOOP  STARTS HERE ========\n",
    "        ## ========================================\n",
    "\n",
    "        car_warn_left = False\n",
    "        car_warn_right = False\n",
    "\n",
    "        clock = pygame.time.Clock()\n",
    "        manual_control.logging.info(\"[GAMELOOP] -> Starting loop...\")\n",
    "        while True:\n",
    "            if args.sync:\n",
    "                sim_world.tick()\n",
    "            clock.tick_busy_loop(args.fps)\n",
    "            if controller.parse_events(client, world, clock, args.sync):\n",
    "                return\n",
    "\n",
    "            # BLIND SPOT DETECTION: Check if there is any vehicle in the blind spot and allert the user by message\n",
    "            current_light = player_vehicle.get_light_state()\n",
    "            if not((current_light & carla.VehicleLightState.LeftBlinker) and (current_light & carla.VehicleLightState.RightBlinker)):\n",
    "\n",
    "                # LEFT blinker check\n",
    "                if current_light & carla.VehicleLightState.LeftBlinker:\n",
    "                    car_warn_left = True # TODO: Implement logic for left blinker from sensors\n",
    "                    if car_warn_left:\n",
    "                        manual_control.logging.info(\"[GAMELOOP | TRIGGER] -> Car detected on the LEFT side\")\n",
    "                        mqtt_send_message(MQTT_TOPIC, \"[WARNING] Car detected on the LEFT side\")\n",
    "                    break\n",
    "\n",
    "                # RIGHT blinker check\n",
    "                if current_light & carla.VehicleLightState.RightBlinker:\n",
    "                    car_warn_right = True # TODO: Implement logic for right blinker from sensors\n",
    "                    if car_warn_right:\n",
    "                        manual_control.logging.info(\"[GAMELOOP | TRIGGER] -> Car detected on the RIGHT side\")\n",
    "                        mqtt_send_message(MQTT_TOPIC, \"[WARNING] -> Car detected on the RIGHT side\")\n",
    "                    break\n",
    "\n",
    "            # ACTIVE INTERVENTION: If a car is detected and the user tries to change lane, make intervention\n",
    "            if car_warn_left or car_warn_right:\n",
    "                # TODO: Check the user movement and make intervention\n",
    "                pass\n",
    "\n",
    "            car_warn_left = False\n",
    "            car_warn_right = False\n",
    "\n",
    "            world.tick(clock)\n",
    "            world.render(display)\n",
    "            pygame.display.flip()\n",
    " \n",
    "    finally:\n",
    "\n",
    "        if original_settings:\n",
    "            sim_world.apply_settings(original_settings)\n",
    "\n",
    "        if (world and world.recording_enabled):\n",
    "            client.stop_recorder()\n",
    "\n",
    "        if world is not None:\n",
    "            world.destroy()\n",
    "\n",
    "        pygame.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb731c5",
   "metadata": {},
   "source": [
    "This cell contains the configuration for the game loop, including argument parsing and logging setup.\n",
    "\n",
    "> To configure the game loop, you can modify the `gameSetup` function to include additional parameters or change the default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed18661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_setup(client=None, sim_world=None):\n",
    "    argparser = manual_control.argparse.ArgumentParser(\n",
    "        description='CARLA Manual Control Client')\n",
    "    argparser.add_argument(\n",
    "        '-v', '--verbose',\n",
    "        action='store_true',\n",
    "        dest='debug',\n",
    "        help='print debug information')\n",
    "    argparser.add_argument(\n",
    "        '--host',\n",
    "        metavar='H',\n",
    "        default='127.0.0.1',\n",
    "        help='IP of the host server (default: 127.0.0.1)')\n",
    "    argparser.add_argument(\n",
    "        '-p', '--port',\n",
    "        metavar='P',\n",
    "        default=2000,\n",
    "        type=int,\n",
    "        help='TCP port to listen to (default: 2000)')\n",
    "    argparser.add_argument(\n",
    "        '-a', '--autopilot',\n",
    "        action='store_true',\n",
    "        help='enable autopilot')\n",
    "    argparser.add_argument(\n",
    "        '--res',\n",
    "        metavar='WIDTHxHEIGHT',\n",
    "        default='1280x720',\n",
    "        help='window resolution (default: 1280x720)')\n",
    "    argparser.add_argument(\n",
    "        '--filter',\n",
    "        metavar='PATTERN',\n",
    "        default='vehicle.*',\n",
    "        help='actor filter (default: \"vehicle.*\")')\n",
    "    argparser.add_argument(\n",
    "        '--generation',\n",
    "        metavar='G',\n",
    "        default='2',\n",
    "        help='restrict to certain actor generation (values: \"1\",\"2\",\"All\" - default: \"2\")')\n",
    "    argparser.add_argument(\n",
    "        '--rolename',\n",
    "        metavar='NAME',\n",
    "        default='hero',\n",
    "        help='actor role name (default: \"hero\")')\n",
    "    argparser.add_argument(\n",
    "        '--gamma',\n",
    "        default=2.2,\n",
    "        type=float,\n",
    "        help='Gamma correction of the camera (default: 2.2)')\n",
    "    argparser.add_argument(\n",
    "        '--sync',\n",
    "        action='store_true',\n",
    "        help='Activate synchronous mode execution')\n",
    "    args = argparser.parse_args()\n",
    "\n",
    "    args.width, args.height = [int(x) for x in args.res.split('x')]\n",
    "\n",
    "    args.fps = 60\n",
    "\n",
    "    args.steering_wheel = IS_STEERING_WHEEL\n",
    "\n",
    "    args.filter = CAR_MODEL\n",
    "\n",
    "    log_level = manual_control.logging.DEBUG if args.debug else manual_control.logging.INFO\n",
    "    manual_control.logging.basicConfig(format='%(levelname)s: %(message)s', level=log_level)\n",
    "\n",
    "    manual_control.logging.info('[LOG] -> Listening to server %s:%s', args.host, args.port)\n",
    "\n",
    "    print(__doc__)\n",
    "\n",
    "    try:\n",
    "        game_loop(args, client=client, sim_world=sim_world)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        manual_control.logging.info('[GAMELOOP] -> Cancelled by user. Bye!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e983cf",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c7558e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [LOG] -> Listening to server 127.0.0.1:2000\n",
      "INFO: [GAMELOOP] -> Using existing CARLA client instance\n",
      "INFO: [GAMELOOP] -> Using existing CARLA world instance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [GAMELOOP] -> Vehicle sensors setup complete\n",
      "INFO: [GAMELOOP] -> Sensors registered and listening for data\n",
      "INFO: [GAMELOOP] -> Controller initialized with KEYBOARD support\n",
      "INFO: [GAMELOOP] -> Starting loop...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [MQTT] Connected (code 0)\n",
      "Left turn signal is ON\n",
      "Left turn signal is OFF\n",
      "Right turn signal is ON\n",
      "Right turn signal is OFF\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "game_setup(client=carla_client, sim_world=world)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
